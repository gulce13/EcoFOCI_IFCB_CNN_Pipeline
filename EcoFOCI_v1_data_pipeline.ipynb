{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PIPELINE to use classifier during the Cruise <br>\n",
    "1-Convert roi to png (you will need pyifcb environment for this step)<br>\n",
    "2-Make csv files with png imagepathways<br>\n",
    "3-Process the images for tensorflow classifier <br>\n",
    "4-Load and apply the classifier<br>\n",
    "5-Plot 20 random images and predicted labels with and without detritus<br>\n",
    "6-Merge the classified csv files for a day <br>\n",
    "7-Summarize the counts of groups per day \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you will need a Python 3.10.12 environment to upload pyifcb package ,it doesnt work with new versions\n",
    "pip install git+https://github.com/joefutrelle/pyifcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1 ROI TO PNG CONVERSION\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import ifcb  # Assuming ifcb is the correct module for opening .roi files\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing the .roi files\n",
    "directory_path = r\"D:\\Dyson-June2024-Data\"\n",
    "\n",
    "# Define the start and end filenames for the range you want to process\n",
    "start_file = \"D20240622T000637_IFCB165.roi\"\n",
    "end_file = \"D20240622T062658_IFCB165.roi\"\n",
    "\n",
    "# Find all .roi files in the directory\n",
    "all_roi_files = glob.glob(os.path.join(directory_path, '*.roi'))\n",
    "\n",
    "# Filter the list for files within the specified range\n",
    "filtered_roi_files = [file for file in all_roi_files if start_file <= os.path.basename(file) <= end_file]\n",
    "\n",
    "# Iterate over each filtered .roi file\n",
    "for roi_file in filtered_roi_files:\n",
    "    try:\n",
    "        # Extract the base filename (without the extension) to use as the folder name\n",
    "        base_filename = os.path.splitext(os.path.basename(roi_file))[0]\n",
    "        \n",
    "        # Construct the path for the new folder\n",
    "        new_folder_path = os.path.join(directory_path, base_filename)\n",
    "\n",
    "        # Create the new folder if it doesn't exist\n",
    "        os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "        # Open the .roi file to access the image data\n",
    "        with ifcb.open_raw(roi_file) as sample_bin:\n",
    "            # Iterate over each image in sample_bin.images\n",
    "            for index, (image_name, image_data) in enumerate(sample_bin.images.items(), start=1):  # Start from 1\n",
    "                # Ensure that image data is converted to an appropriate integer type\n",
    "                if not np.issubdtype(image_data.dtype, np.integer):\n",
    "                    # Convert floating-point image data to uint8 (common for images)\n",
    "                    image_data = (255 * (image_data / np.max(image_data))).astype(np.uint8)\n",
    "                \n",
    "                # Convert the image data to a PIL Image object\n",
    "                img = Image.fromarray(image_data)\n",
    "                \n",
    "                # Format the filename with the incremented part\n",
    "                filename = f\"{base_filename}.{index:05}.png\"\n",
    "                \n",
    "                # Construct the full path for the output file within the new folder\n",
    "                output_path = os.path.join(new_folder_path, filename)\n",
    "                \n",
    "                # Save the image\n",
    "                img.save(output_path)\n",
    "\n",
    "                # Free memory by closing the image object after saving\n",
    "                img.close()  # Explicitly close the image to release resources\n",
    "                del img  # Ensure the object is deleted to free up memory\n",
    "\n",
    "        print(f\"Processed and saved images for: {roi_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # If there's an error processing a specific file, it will be logged, and the process will continue\n",
    "        print(f\"Error processing {roi_file}: {e}\")\n",
    "\n",
    "# Process complete\n",
    "print(\"Processing complete for all files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2- MAKE THC CSV FILES\n",
    "#Parent directory, make csv file of each image folder \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the parent directory containing the folders\n",
    "parent_dir = r\"D:\\Dyson-June2024-Data\"\n",
    "\n",
    "# Iterate through each folder in the parent directory\n",
    "for folder_name in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, folder_name)\n",
    "\n",
    "    # Ensure the path is a directory (i.e., a folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # List to hold file paths\n",
    "        image_paths = []\n",
    "\n",
    "        # Iterate over the files in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".png\"):  # Assuming images are in PNG format\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                image_paths.append(img_path)\n",
    "\n",
    "        # Create a DataFrame with the image paths\n",
    "        df = pd.DataFrame(image_paths, columns=['Image_Path'])\n",
    "\n",
    "        # Define the CSV file name using the folder name\n",
    "        csv_path = os.path.join(folder_path, f\"{folder_name}_Image_Path.csv\")\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(csv_path, index=False)\n",
    "\n",
    "        print(f\"Image paths for folder '{folder_name}' saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1- PREPROCESS THE IMAGES DEFINE FUNCTIONS\n",
    "#Preprocess the image and saving function\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_input(image):\n",
    "    fixed_size = 128  # Final image should be 128 x 128\n",
    "    image_size = image.shape[:2]  # Gets the (y_dim, x_dim) for each image\n",
    "\n",
    "    # The ratio needed to make the longest side of the image 128 pixels\n",
    "    ratio = float(fixed_size) / max(image_size)\n",
    "\n",
    "    # Calculates the new size by multiplying each dimension by the ratio\n",
    "    new_size = tuple([int(x * ratio) for x in image_size])\n",
    "\n",
    "    # Resizes the image to the new size\n",
    "    img = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "\n",
    "    # Calculates the possible padding needed for the x and y dimensions\n",
    "    delta_w = fixed_size - new_size[1]\n",
    "    delta_h = fixed_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # Makes a black border of 128x128 pixels around the image\n",
    "    color = [0, 0, 0]  # RGB = 0,0,0 -> Black\n",
    "    rescaled_image = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    \n",
    "    return rescaled_image\n",
    "\n",
    "def process_and_save_images(folder_path, destination_folder):\n",
    "    # Create a new destination folder for the processed images\n",
    "    processed_folder_name = os.path.basename(folder_path) + \"_processed\"\n",
    "    processed_folder_path = os.path.join(destination_folder, processed_folder_name)\n",
    "    os.makedirs(processed_folder_path, exist_ok=True)\n",
    "\n",
    "    # Iterate through each image in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".png\"):  # Assuming images are in PNG format\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Load the image\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            # Check if the image was loaded successfully\n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not load image {img_path}. Skipping this file.\")\n",
    "                continue\n",
    "\n",
    "            # Process the image\n",
    "            processed_image = preprocess_input(image)\n",
    "\n",
    "            # Convert the processed image to grayscale\n",
    "            processed_gray = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Save the processed grayscale image as an .npy file\n",
    "            npy_path = os.path.join(processed_folder_path, filename.replace('.png', '.npy'))\n",
    "            np.save(npy_path, processed_gray)\n",
    "\n",
    "    print(f\"Processed images saved as .npy files to {processed_folder_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 ITERATE THROUGH FOLDERS AND APPLY PREPROCESSING (THIS CAN TAKE TIME)\n",
    "# Define the parent directory containing the folders\n",
    "# Define the parent directory containing the folders\n",
    "parent_dir = r\"D:\\EndSeason-DataDump22\\DY22_06_IFCB\\images_2022\\D202205\"\n",
    "\n",
    "# Create the new destination directory for all processed folders\n",
    "destination_folder = os.path.join(parent_dir, \"D202205_class_processed\")\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through each folder in the parent directory\n",
    "for folder_name in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, folder_name)\n",
    "\n",
    "    # Ensure the path is a directory (i.e., a folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"Processing folder: {folder_name}\")\n",
    "        process_and_save_images(folder_path, destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1. APPLYING THE SAME MODEL FOR STICKED IMAGES AFTER THE DATA FROM 09/10/2024 <br>\n",
    "# (DY2410_model_v6, is the same model with 1--natural_epcoh_model_v5 just introduced the stucked blurry images in the flow cell as detritus and some tintinnid images s ciliate\n",
    "\n",
    "#3. LOAD THE MODEL AND MAP THE LABELS\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = r\"C:\\Users\\kurta\\OneDrive - UW\\Desktop\\During_Fall24_Cruise\\training_folder\\DY2024_model_v6.h5\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Updated class mapping with 'Corethron' added #THIS WILL CHANGE FOR EACH CLASSIFIER\n",
    "class_mapping = {\n",
    "    'Chaetoceros': 0,\n",
    "    'Ciliate': 1,\n",
    "    'Corethron': 2,\n",
    "    'Coscinodiscus': 3,\n",
    "    'Cryptophyte': 4,\n",
    "    'Detritus': 5,\n",
    "    'Dictyocha': 6,\n",
    "    'Dinoflagellate': 7,\n",
    "    'Elongated': 8,\n",
    "    'Euglena': 9,\n",
    "    'Nanoflagellate': 10,\n",
    "    'Pennate': 11,\n",
    "    'Thalassiosira': 12\n",
    "}\n",
    "\n",
    "# Initialize the LabelEncoder and fit it with the classes\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(list(class_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 APPLY CLASSIFIER MODEL\n",
    "#3.2a second working version\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory where all CSV files will be saved\n",
    "csv_output_folder = os.path.join(parent_dir, \"classification_results\")\n",
    "os.makedirs(csv_output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through each folder in the parent directory\n",
    "for folder_name in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, folder_name)\n",
    "    \n",
    "    # Check if the path is a directory\n",
    "    if os.path.isdir(folder_path) and folder_name.endswith(\"_processed\"):\n",
    "        print(f\"Processing folder: {folder_name}\")\n",
    "        \n",
    "        # List to hold image data and paths\n",
    "        image_data = []\n",
    "        image_paths = []\n",
    "\n",
    "        # Iterate through each .npy file in the processed folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".npy\"):\n",
    "                npy_path = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    image = np.load(npy_path)  # Load the .npy file\n",
    "                    image = np.expand_dims(image, axis=-1)  # Add the channel dimension if needed\n",
    "                    image = np.expand_dims(image, axis=0)  # Add the batch dimension\n",
    "                    image_data.append(image)\n",
    "                    image_paths.append(npy_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {npy_path}: {e}\")\n",
    "\n",
    "        # Check if there are images to process\n",
    "        if len(image_data) == 0:\n",
    "            print(f\"No valid .npy files found in folder: {folder_name}. Skipping...\")\n",
    "            continue  # Skip to the next folder\n",
    "\n",
    "        # Convert list of images to a single numpy array\n",
    "        try:\n",
    "            image_data = np.vstack(image_data)\n",
    "        except ValueError as ve:\n",
    "            print(f\"Error concatenating images in folder {folder_name}: {ve}\")\n",
    "            continue\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.predict(image_data)\n",
    "\n",
    "        # Convert predictions from one-hot encoded format to label indices\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "        # Convert the integer predictions back to their original labels\n",
    "        predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "        # Create a DataFrame to hold the results\n",
    "        results_df = pd.DataFrame({\n",
    "            'Image_Path': image_paths,\n",
    "            'Predicted_Label': predicted_labels\n",
    "        })\n",
    "\n",
    "        # Define the path to save the CSV file in the parent folder\n",
    "        output_csv_path = os.path.join(csv_output_folder, f\"{folder_name}_classification_results.csv\")\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        results_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "        print(f\"Classification results saved to {output_csv_path}\")\n",
    "\n",
    "# Process complete\n",
    "print(\"Processing complete for all folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1 ITERATE  THROUGH the CLASSIFIED FILES AND PLOT RANDOM 20 IMAGES\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the folder containing the classification results CSV files\n",
    "classification_folder = r\"D:\\DY2410\\D20240909\\D20241017_processed\\classification_results\"\n",
    "\n",
    "# Iterate through each CSV file in the classification folder\n",
    "for csv_file in os.listdir(classification_folder):\n",
    "    if csv_file.endswith(\"_classification_results.csv\"):\n",
    "        # Construct the full path to the CSV file\n",
    "        csv_path = os.path.join(classification_folder, csv_file)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        results_df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Sample 20 random images from the DataFrame\n",
    "        random_sample = results_df.sample(n=20, random_state=42)  # random_state ensures reproducibility\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(25, 10))\n",
    "\n",
    "        for i, (index, row) in enumerate(random_sample.iterrows()):\n",
    "            # Get the image path and predicted label\n",
    "            image_path = row['Image_Path']\n",
    "            predicted_label = row['Predicted_Label']\n",
    "\n",
    "            # Load the image from the .npy file\n",
    "            image = np.load(image_path)\n",
    "\n",
    "            # Plot the image\n",
    "            plt.subplot(4, 5, i + 1)  # 4 rows, 5 columns grid\n",
    "            plt.imshow(image, cmap='gray')  # Assuming the image is grayscale\n",
    "            plt.title(f\"Predicted: {predicted_label}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Extract the base name (without the \"_processed_classification_results.csv\" part)\n",
    "        base_name = csv_file.split(\"_processed_classification_results.csv\")[0]\n",
    "\n",
    "        # Define the path to save the PNG file\n",
    "        output_png_path = os.path.join(classification_folder, f\"{base_name}.png\")\n",
    "\n",
    "        # Save the plot as a PNG file\n",
    "        plt.savefig(output_png_path)\n",
    "        plt.close()  # Close the plot to free up memory\n",
    "\n",
    "        print(f\"Random 20 images plot saved as {output_png_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2 Exclude detritus images to the plots\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the folder containing the classification results CSV files\n",
    "classification_folder = r\"D:\\DY2410\\D20240922\\D20241022_processed\\classification_results\"\n",
    "\n",
    "# Iterate through each CSV file in the classification folder\n",
    "for csv_file in os.listdir(classification_folder):\n",
    "    if csv_file.endswith(\"_classification_results.csv\"):\n",
    "        # Construct the full path to the CSV file\n",
    "        csv_path = os.path.join(classification_folder, csv_file)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        results_df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filter out images classified as \"Detritus\"\n",
    "        filtered_df = results_df[results_df['Predicted_Label'] != \"Detritus\"]\n",
    "\n",
    "        # If no images remain after filtering, skip to the next CSV file\n",
    "        if filtered_df.empty:\n",
    "            print(f\"No non-Detritus images found in {csv_file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Sample 20 random images from the filtered DataFrame, or less if fewer than 20 non-Detritus images exist\n",
    "        random_sample = filtered_df.sample(n=min(20, len(filtered_df)), random_state=42)  # random_state ensures reproducibility\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(25, 10))\n",
    "\n",
    "        for i, (index, row) in enumerate(random_sample.iterrows()):\n",
    "            # Get the image path and predicted label\n",
    "            image_path = row['Image_Path']\n",
    "            predicted_label = row['Predicted_Label']\n",
    "\n",
    "            # Load the image from the .npy file\n",
    "            image = np.load(image_path)\n",
    "\n",
    "            # Plot the image\n",
    "            plt.subplot(4, 5, i + 1)  # 4 rows, 5 columns grid\n",
    "            plt.imshow(image, cmap='gray')  # Assuming the image is grayscale\n",
    "            plt.title(f\"Predicted: {predicted_label}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Extract the base name (without the \"_processed_classification_results.csv\" part)\n",
    "        base_name = csv_file.split(\"_processed_classification_results.csv\")[0]\n",
    "\n",
    "        # Define the path to save the PNG file\n",
    "        output_png_path = os.path.join(classification_folder, f\"{base_name}_non_det.png\")\n",
    "\n",
    "        # Save the plot as a PNG file\n",
    "        plt.savefig(output_png_path)\n",
    "        plt.close()  # Close the plot to free up memory\n",
    "\n",
    "        print(f\"Random 20 non-Detritus images plot saved as {output_png_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 merge the all csv files per day\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Directory containing the CSV files\n",
    "csv_directory = r\"D:\\DY2410\\D20240922\\D20241022_processed\\classification_results\"\n",
    "\n",
    "# Find all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(csv_directory, '*.csv'))\n",
    "\n",
    "# List to hold dataframes from each CSV file\n",
    "df_list = []\n",
    "\n",
    "# Iterate over each CSV file and read it into a dataframe\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 summarize the results\n",
    "import pandas as pd\n",
    "\n",
    "# Summarize the Predicted_Label column\n",
    "label_summary = merged_df['Predicted_Label'].value_counts()\n",
    "\n",
    "# Convert the summary to a DataFrame for saving as CSV\n",
    "summary_df = label_summary.reset_index()\n",
    "summary_df.columns = ['Predicted_Label', 'Count']\n",
    "\n",
    "# Path to save the output CSV file\n",
    "output_path = r\"D:\\DY2410\\D20240922_summary.csv\"\n",
    "\n",
    "# Save the summary as a CSV file\n",
    "summary_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Summary saved at: {output_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyifcb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
